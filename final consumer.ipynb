{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "578fe77c-1cf2-45a8-80b0-cadd100daf54",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1-library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88571490-1a01-407c-9316-ea86cebc56d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "from pandas_datareader import data as pdr\n",
    "#import fix_yahoo_finance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26c588c4-72c4-4bbf-ae4e-e3e367b4e883",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd8b97ef-45cd-4edc-b60c-1ff7a38dd7fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### ceation des alertes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2db51be8-1390-44ca-a549-cf96d311a51c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "alerte prix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a0dc466-6968-4495-8be6-e5107176e54a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_percentage_difference(true_value, predicted_value):\n",
    "        return abs((predicted_value - true_value) / true_value) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac5bbfa-9e91-43fa-8944-8be1755edd7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def send_alert():\n",
    "    # Email configurations\n",
    "    smtp_server = 'smtp.gmail.com'\n",
    "    smtp_port = 587\n",
    "    sender_email ='nourhenerbei123@gmail.com'\n",
    "    sender_password = 'zkbiqcrfgxnzfqdw'\n",
    "    receiver_email = 'nourhene.rbei@etudiant-fst.utm.tn'\n",
    "    subject = 'Changement significatif du prix du titre demain'\n",
    "    message = '''Cher utilisateur,\n",
    "\n",
    "    Nous tenons à vous informer qu'un changement significatif est prévu dans le prix du titre que vous suivez pour demain.\n",
    "    Nous vous recommandons de suivre de près ces développements et de prendre les mesures appropriées en fonction de vos objectifs financiers et de votre   stratégie d'investissement.\n",
    "\n",
    "    Veuillez noter que cette notification est envoyée automatiquement dès qu'un changement significatif est détecté dans le prix du titre que vous suivez. Nous faisons de notre mieux pour vous tenir informé en temps réel afin que vous puissiez prendre des décisions éclairées.\n",
    "\n",
    "    Cordialement,\n",
    "    Votre équipe de suivi des marchés financiers'''\n",
    "\n",
    "    # Create a MIME message\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "    msg['Subject'] = subject\n",
    "\n",
    "    # Attach the message to the email\n",
    "    msg.attach(MIMEText(message, 'plain'))\n",
    "\n",
    "    # Connect to the SMTP server\n",
    "    server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "    server.starttls()\n",
    "\n",
    "    # Login to the sender's email account\n",
    "    server.login(sender_email, sender_password)\n",
    "\n",
    "    # Send the email\n",
    "    server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "\n",
    "    # Disconnect from the SMTP server\n",
    "    server.quit()\n",
    "\n",
    "    return print('Email sent successfully.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "768b4747-8399-4f58-82c7-b67bdf7f335c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "alerte volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81a4e38a-c89b-4b7f-9a72-f9ee61bf22fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def send_alert_volume():\n",
    "    # Email configurations\n",
    "    smtp_server = 'smtp.gmail.com'\n",
    "    smtp_port = 587\n",
    "    sender_email ='nourhenerbei123@gmail.com'\n",
    "    sender_password = 'zkbiqcrfgxnzfqdw'\n",
    "    receiver_email = 'nourhene.rbei@etudiant-fst.utm.tn'\n",
    "    subject = 'Changement significatif du volume du titre demain'\n",
    "    message = '''Cher utilisateur,\n",
    "\n",
    "    Nous tenons à vous informer qu'un changement significatif est prévu dans le volume du titre que vous suivez pour demain.\n",
    "    Nous vous recommandons de suivre de près ces développements et de prendre les mesures appropriées en fonction de vos objectifs financiers et de votre   stratégie d'investissement.\n",
    "\n",
    "    Veuillez noter que cette notification est envoyée automatiquement dès qu'un changement significatif est détecté dans le prix du titre que vous suivez. Nous faisons de notre mieux pour vous tenir informé en temps réel afin que vous puissiez prendre des décisions éclairées.\n",
    "\n",
    "    Cordialement,\n",
    "    Votre équipe de suivi des marchés financiers'''\n",
    "\n",
    "    # Create a MIME message\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "    msg['Subject'] = subject\n",
    "\n",
    "    # Attach the message to the email\n",
    "    msg.attach(MIMEText(message, 'plain'))\n",
    "\n",
    "    # Connect to the SMTP server\n",
    "    server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "    server.starttls()\n",
    "\n",
    "    # Login to the sender's email account\n",
    "    server.login(sender_email, sender_password)\n",
    "\n",
    "    # Send the email\n",
    "    server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "\n",
    "    # Disconnect from the SMTP server\n",
    "    server.quit()\n",
    "\n",
    "    return print('Email sent successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d84ac5f-3b0b-42f1-9880-44d1bd3e8178",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "connexion à a base de données \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa82c89-92a1-4123-a37f-f3f43dbf2a5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "driver = \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "\n",
    "database_host = \"portefeuille.database.windows.net\"\n",
    "database_port = \"1433\" # update if you use a non-default port\n",
    "database_name = \"portefeuille\"\n",
    "table = \"DIM_DATE\"\n",
    "user = \"portefeuille\"\n",
    "password = \"Noursharm_123\"\n",
    "url=\"jdbc:sqlserver://portefeuille.database.windows.net:1433;database=portefeuille;user=portefeuille@portefeuille;password=Noursharm_123;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dee10f4-ee9f-49f8-a881-89caca60322b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### création de modèle de prédiction de fluctuation du prix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17d9875f-5ac0-43b6-99cc-e22ab1e803de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "créer la table de prédiction close "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf541f28-7256-439b-acca-aa8aa1d5c7b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "def table_de_pred(table_fait,id_action):\n",
    "    filtered_table = table_fait.filter(table_fait.ID_INFO_ACTION == id_action).select(\"ID_DATE\", \"CLOSE\",'ID_INFO_ACTION')\n",
    "   # Convert ID_DATE from string to date format\n",
    "    converted_table = filtered_table.withColumn(\"ID_DATE\", to_date(filtered_table.ID_DATE, \"yyyyMMdd\"))\n",
    "    #converted_table.show()\n",
    "    sorted_table = converted_table.orderBy(\"ID_DATE\")\n",
    "    #sorted_table.show()\n",
    "    #endog = sorted_table.select('ID_DATE', 'CLOSE','ID_INFO_ACTION').rdd.collect()\n",
    "    return sorted_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2c74b82-beb5-4225-816a-26fe9e02e9f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "vérifier si la prédiction de l'action x à la date y  éxiste ou non , si oui on passe , si non on l'enregistre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed8b543-f7b0-4799-ab9e-df11263a7eac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def verif_prediction(row_df): \n",
    "    prediction_table = (spark.read.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"close_prediction\").load())\n",
    "    existing_row = prediction_table.filter(\n",
    "        (col(\"date_\") == row_df.collect()[0][0]) &\n",
    "        (col(\"ticker\") == row_df.collect()[0][3])\n",
    "    ).count() \n",
    "    if existing_row == 0:\n",
    "        updated_row_df = row_df.withColumn(\"ticker\",\n",
    "                                           when(col(\"ticker\") == 1, \"AAL\")\n",
    "                                           .when(col(\"ticker\") == 2, \"AAPL\")\n",
    "                                           .when(col(\"ticker\") == 3, \"AMZN\")\n",
    "                                           .when(col(\"ticker\") == 4, \"GOOG\")\n",
    "                                           .when(col(\"ticker\") == 5, \"ICE\")\n",
    "                                           .when(col(\"ticker\") == 6, \"MSFT\")\n",
    "                                           .otherwise(col(\"ticker\"))\n",
    "                                          )\n",
    "        updated_row_df.write.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"close_prediction\").mode(\"append\").save()\n",
    "    else:\n",
    "        #raise Exception(\"Operation canceled. Conditions already exist in table_fait.\")\n",
    "        return print(\"row already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b8b74c0-dc13-43ab-8653-398e8677d490",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "model de prédiction et il stock le résultat dans une table séparée dans la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87970bdd-9202-4617-bf6b-19c75db9dcb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from datetime import datetime\n",
    "\n",
    "def predict_close_price(table_fait, id_action):\n",
    "    sorted_table = table_de_pred(table_fait, id_action)\n",
    "    endog = sorted_table.select('ID_DATE', 'CLOSE').rdd.collect()\n",
    "    train_size = len(endog) - 1  # 80% for training, 20% for testing\n",
    "    train_data = endog[:train_size]\n",
    "    test_data = endog[train_size:]\n",
    "\n",
    "    # Split the data into features (X) and target variable (y)\n",
    "    X_train = np.array([(datetime.combine(row[0], datetime.min.time()) - datetime(1970, 1, 1)).days for row in train_data]).reshape(-1, 1)\n",
    "    y_train = np.array([row[1] for row in train_data])\n",
    "    X_test = np.array([(datetime.combine(row[0], datetime.min.time()) - datetime(1970, 1, 1)).days for row in test_data]).reshape(-1, 1)\n",
    "    y_test = np.array([row[1] for row in test_data])\n",
    "\n",
    "    # Create and fit the Gradient Boosting Regressor model\n",
    "    model = GradientBoostingRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get the predicted values for the test set\n",
    "    predicted_values = model.predict(X_test)\n",
    "\n",
    "    # Print the predicted values, true values, and dates\n",
    "    schema = StructType([\n",
    "        StructField(\"date_\", StringType(), nullable=False),\n",
    "        StructField(\"close_\", FloatType(), nullable=False),\n",
    "        StructField(\"predicted_close\", FloatType(), nullable=False),\n",
    "        StructField(\"ticker\", IntegerType(), nullable=False)\n",
    "    ])\n",
    "    alert_threshold = 5 \n",
    "    for i in range(len(predicted_values)):\n",
    "        print(\"Date:\", test_data[i][0].strftime(\"%Y%m%d\"))\n",
    "        print(\"Predicted value:\", predicted_values[i])\n",
    "        print(\"True value:\", y_test[i])\n",
    "        percentage_difference = calculate_percentage_difference(y_test[i], predicted_values[i])\n",
    "        print(\"Percentage difference:\", percentage_difference)\n",
    "        print(\"AAPL\")\n",
    "        row = (test_data[i][0].strftime(\"%Y%m%d\"), float(y_test[i]), float(predicted_values[i]), id_action)\n",
    "        row_df = spark.createDataFrame([row], schema=schema)\n",
    "        row_df.show()\n",
    "        verif_prediction(row_df)\n",
    "\n",
    "        if percentage_difference > alert_threshold:\n",
    "            # Trigger alert or take appropriate action\n",
    "            send_alert()\n",
    "\n",
    "    return predicted_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b791bbb-b41f-496c-8378-0ac47f9cf18d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### création de modèle de prédiction de volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d4788ea-0dd9-401c-9d01-838e0ab00c28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "def table_de_pred_volume(table_fait,id_action):\n",
    "    filtered_table = table_fait.filter(table_fait.ID_INFO_ACTION == id_action).select(\"ID_DATE\", \"VOLUME\",'ID_INFO_ACTION')\n",
    "   # Convert ID_DATE from string to date format\n",
    "    converted_table = filtered_table.withColumn(\"ID_DATE\", to_date(filtered_table.ID_DATE, \"yyyyMMdd\"))\n",
    "    #converted_table.show()\n",
    "    sorted_table = converted_table.orderBy(\"ID_DATE\")\n",
    "    #sorted_table.show()\n",
    "    return sorted_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c531541b-0607-4fe7-9f47-d3d3a0a02456",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "def verif_volume_prediction(row_df):\n",
    "    prediction_table = spark.read.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"volume_prediction\").load()\n",
    "    existing_row = prediction_table.filter(\n",
    "        (col(\"date_\") == row_df.select(\"date_\").collect()[0][0]) &\n",
    "        (col(\"ticker\") == row_df.select(\"ticker\").collect()[0][0])\n",
    "    ).count()\n",
    "    if existing_row == 0:\n",
    "        updated_row_df = row_df.withColumn(\"ticker\",\n",
    "                                           when(col(\"ticker\") == 1, \"AAL\")\n",
    "                                           .when(col(\"ticker\") == 2, \"AAPL\")\n",
    "                                           .when(col(\"ticker\") == 3, \"AMZN\")\n",
    "                                           .when(col(\"ticker\") == 4, \"GOOG\")\n",
    "                                           .when(col(\"ticker\") == 5, \"ICE\")\n",
    "                                           .when(col(\"ticker\") == 6, \"MSFT\")\n",
    "                                           .otherwise(col(\"ticker\"))\n",
    "                                          )\n",
    "        updated_row_df.write.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"volume_prediction\").mode(\"append\").save()\n",
    "    else:\n",
    "        print(\"Row already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84275b03-b20b-45d0-8d6a-00a0809f81f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from datetime import datetime\n",
    "\n",
    "def predict_volume_price(table_fait, id_action):\n",
    "    sorted_table = table_de_pred_volume(table_fait,id_action)\n",
    "    endog = sorted_table.select('ID_DATE', 'VOLUME').rdd.collect()\n",
    "    train_size = len(endog) - 1  # 80% for training, 20% for testing\n",
    "    train_data = endog[:train_size]\n",
    "    test_data = endog[train_size:]\n",
    "\n",
    "    # Split the data into features (X) and target variable (y)\n",
    "    X_train = np.array([(datetime.combine(row[0], datetime.min.time()) - datetime(1970, 1, 1)).days for row in train_data]).reshape(-1, 1)\n",
    "    y_train = np.array([row[1] for row in train_data])\n",
    "    X_test = np.array([(datetime.combine(row[0], datetime.min.time()) - datetime(1970, 1, 1)).days for row in test_data]).reshape(-1, 1)\n",
    "    y_test = np.array([row[1] for row in test_data])\n",
    "\n",
    "    # Create and fit the Gradient Boosting Regressor model\n",
    "    model = GradientBoostingRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get the predicted values for the test set\n",
    "    predicted_values = model.predict(X_test)\n",
    "\n",
    "    # Print the predicted values, true values, and dates\n",
    "    schema = StructType([\n",
    "        StructField(\"date_\", StringType(), nullable=False),\n",
    "        StructField(\"volume\", FloatType(), nullable=False),\n",
    "        StructField(\"volume_pred\", FloatType(), nullable=False),\n",
    "        StructField(\"ticker\", StringType(), nullable=False)\n",
    "    ])\n",
    "    alert_threshold = 50\n",
    "    \n",
    "    for i in range(len(predicted_values)):\n",
    "        print(\"Date:\", test_data[i][0].strftime(\"%Y%m%d\"))\n",
    "        print(\"Predicted value:\", predicted_values[i])\n",
    "        print(\"True value:\", y_test[i])\n",
    "        percentage_difference = calculate_percentage_difference(y_test[i], predicted_values[i])\n",
    "        print(\"Percentage difference:\", percentage_difference)\n",
    "        #print(\"AAPL\")\n",
    "        row = (test_data[i][0].strftime(\"%Y%m%d\"), float(y_test[i]), float(predicted_values[i]), id_action)\n",
    "        row_df = spark.createDataFrame([row], schema=schema)\n",
    "        row_df.show()\n",
    "        verif_volume_prediction(row_df)\n",
    "\n",
    "        if percentage_difference > alert_threshold:\n",
    "            # Trigger alert or take appropriate action\n",
    "            send_alert_volume()\n",
    "\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcdf3daa-bb16-4bed-8df9-1c64de4d7d3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####mise à jour de DWH \n",
    "vérification et mise à jour des dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c53a1d-d266-4089-8e09-e760d542c447",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def checkandaddskdate(new_date_id, dim_date, data):\n",
    "    # Check if ID_DATE already exists in dim_date DataFrame\n",
    "    existing_date = dim_date.filter(col(\"ID_DATE\") == new_date_id).count()\n",
    "    \n",
    "    # If ID_DATE does not exist, add the new row to the dim_date DataFrame and save it to \"DIM_DATE_test\"\n",
    "    if existing_date == 0:\n",
    "        new_date_row = {\n",
    "            \"ID_DATE\": new_date_id,\n",
    "            \"YEAR\": int(new_date_id[:4]),\n",
    "            \"MONTH\": int(new_date_id[4:6]),\n",
    "            \"DAY\": int(new_date_id[6:])\n",
    "        }\n",
    "        \n",
    "        # Create the new row DataFrame\n",
    "        new_dm_date_df = spark.createDataFrame([new_date_row])\n",
    "        \n",
    "        # Write the new row DataFrame to \"DIM_DATE_test\" table\n",
    "        new_dm_date_df.write.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"DIM_DATE\").mode(\"append\").save()\n",
    "        \n",
    "    return dim_date\n",
    "\n",
    "#new_date_id = \"20230407\"\n",
    "#updated_dim_date_df = checkandaddskdate(new_date_id, dim_date, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a8ad517-593f-4238-9bc8-5f544541085b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def checkandaddidinfoaction(new_info_id,dim_info,data):\n",
    "    existing_action = dim_info.filter(col(\"SYMBOL\") == data[\"company_name\"]).count()\n",
    "    # Check and add new rows to the dimension table  brand\n",
    "    \n",
    "    if existing_action == 0:\n",
    "        new_action_row = {\n",
    "        \"ID_INFO_ACTION\": new_info_id,\n",
    "        \"SYMBOL\":data[\"company_name\"],\n",
    "        \"LANGUAGE\":\"\",\n",
    "        \"DISPLAY_NAME\":\"\",\n",
    "        \"EXCHANGETIMEZONENAME\":\"\"}\n",
    "        # create the new line for the update\n",
    "        new_dim_info =spark.createDataFrame([new_action_row])\n",
    "        # Write the updated dimension data back to the respective table\n",
    "        new_dim_info.write.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"DIM_INFO_ACT\").mode(\"append\").save()\n",
    "#new_info_id =dim_info.selectExpr(\"MAX(ID_INFO_ACTION) + 1\").first()[0]\n",
    "#updated_dim_action_df = checkandaddidinfoaction(new_info_id,dim_info,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d9f248e-f39e-41db-ab2d-7ebc1067a5d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#new_revenue_id =dim_revenue.selectExpr(\"MAX(ID_REVENUE) + 1\").first()[0]\n",
    "def checkandaddidrevenue(new_revenue_id,dim_revenue,data):\n",
    "    #existing_action = dim_revenue.filter(col(\"TICKER\") == data[\"company_name\"]).count()\n",
    "    # Check and add new rows to the dimension table  brand\n",
    "    existing_action=0\n",
    "    if existing_action == 0:\n",
    "        new_revenue_row = {\n",
    "        \"ID_REVENUE\":new_revenue_id,\n",
    "        \"REVENUE\":\"\",\n",
    "        \"REVENUE_PER_SHARE\":\"\",\n",
    "        \"QUARTERLY_REVENUE_GROWTH\":\"\",\n",
    "        \"GROSS_PROFIT\":\"\",\n",
    "        \"NET_INCOME\":\"\",\n",
    "        \"QUARTERLY_EARNINGS_GROWTH\":\"\",\n",
    "        \"TOTAL_CASH\":\"\",\n",
    "        \"TOTAL_CASH_PER_SHARE\":\"\",\n",
    "        \"TOTAL_DEBT\":\"\",\n",
    "        \"TOTAL_DEBT_EQUITY\":\"\",\n",
    "        \"CURRENT_RATIO\":\"\",\n",
    "        \"TICKER\":data[\"company_name\"]}\n",
    "        # create the new line for the update\n",
    "        new_dim_revenue =spark.createDataFrame([new_revenue_row])\n",
    "        # Write the updated dimension data back to the respective table\n",
    "        new_dim_revenue.write.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"DIM_REVENUE_TTM\").mode(\"append\").save()\n",
    "#checkandaddidrevenue(new_revenue_id,dim_revenue,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1884659e-5010-42e7-958e-38d1f4e29d19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "création des nouveau id and les dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51ff1f3-0e68-4ac8-8e97-f7dadbef7d01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_id_info(data,dim_info): \n",
    "    num1= dim_info.filter(col(\"SYMBOL\") == data[\"company_name\"]).count()\n",
    "    if num1==0 :\n",
    "      new_info_id =dim_info.selectExpr(\"MAX(ID_INFO_ACTION) + 1\").first()[0]\n",
    "    else :\n",
    "      new_info_id = dim_info.filter(col(\"SYMBOL\") == data[\"company_name\"]).select(\"ID_INFO_ACTION\").first()[0]\n",
    "    return new_info_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5db5b1a5-8f59-48d7-987a-7abd1e52d791",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_id_revenue(data,dim_revenue): \n",
    "    num1= dim_revenue.filter(col(\"TICKER\") == data[\"company_name\"]).count()\n",
    "    if num1==0 :\n",
    "      new_revenue_id =dim_revenue.selectExpr(\"MAX(ID_REVENUE) + 1\").first()[0]\n",
    "    else :\n",
    "      new_revenue_id = dim_revenue.filter(col(\"TICKER\") == data[\"company_name\"]).select(\"ID_REVENUE\").first()[0]\n",
    "    return new_revenue_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd12db14-65fb-4d0d-a397-17a5e2adfbbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_id_fact(data, table_fait):\n",
    "    num1 = table_fait.filter(\n",
    "        (col(\"ID_DATE\") == data[\"Date\"]) &\n",
    "        (col(\"CLOSE\") == data[\"Close\"]) &\n",
    "        (col(\"OPEN\") == data[\"Open\"]) &\n",
    "        (col(\"HIGHT\") == data[\"High\"]) &\n",
    "        (col(\"LOW\") == data[\"Low\"]) &\n",
    "        (col(\"VOLUME\") == data[\"Volume\"]) &\n",
    "        (col(\"ADJ_CLOSE\") == data[\"Adj Close\"])\n",
    "    ).count()\n",
    "\n",
    "    if num1 == 0:\n",
    "        new_fact_id = table_fait.selectExpr(\"MAX(ID_ACTION) + 1\").first()[0]\n",
    "    else:\n",
    "        #raise Exception(\"Operation canceled. Conditions already exist in table_fait.\")\n",
    "        return\n",
    "    return new_fact_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5880d4f7-7609-4677-a14b-501fb04d165b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####générer une ligne "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df867687-cba9-4518-8107-796e7e883561",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "mise à jour de la table de fait "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f859c2d7-cf11-4502-a80c-7e095ec06535",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,lit,when\n",
    "def generaterow(data):    \n",
    "    dim_date = (spark.read.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"DIM_DATE\").load())\n",
    "    dim_info= (spark.read.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"DIM_INFO_ACT\").load())\n",
    "    dim_revenue= (spark.read.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"DIM_REVENUE_TTM\").load())\n",
    "    table_fait = (spark.read.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"fact_table\").load())\n",
    "    #dim_info.show()\n",
    "    #dim_revenue\n",
    "    new_info_id =create_id_info(data,dim_info)\n",
    "    new_revenue_id =create_id_revenue(data,dim_revenue)\n",
    "    dim_date = dim_date.withColumnRenamed(\"ID_DATE\", \"NEW_ID_DATE\")\n",
    "    dim_info = dim_info.withColumnRenamed(\"ID_INFO_ACTION\", \"NEW_ID_INFO_ACTION\")\n",
    "    dim_revenue = dim_revenue.withColumnRenamed(\"ID_REVENUE\", \"NEW_ID_REVENUE\")\n",
    "    factID=create_id_fact(data, table_fait)\n",
    "    new_date_id= data['Date']\n",
    "    new_row = {\n",
    "      \"ID_ACTION\":factID,\n",
    "      \"ID_DATE\": data[\"Date\"],\n",
    "      \"ID_INFO_ACTION\":new_info_id,\n",
    "      \"ID_DIVIDEND\":1,\n",
    "      \"OPEN\":data[\"Open\"],\n",
    "      \"HIGHT\":data[\"High\"],\n",
    "      \"LOW\":data[\"Low\"],\n",
    "      \"CLOSE\":data[\"Close\"],\n",
    "      \"VOLUME\": data[\"Volume\"],\n",
    "      \"ADJ_CLOSE\":data[\"Adj Close\"],\n",
    "      \"ID_REVENUE\":new_revenue_id\n",
    "    }    \n",
    "    #new_row_df = spark.createDataFrame([new_row])\n",
    "    # Perform a left join on each dimension table with the new row data to check for existing SKs\n",
    "    new_row_df = spark.createDataFrame([new_row])\n",
    "    new_row_df = new_row_df.join(dim_date, new_row_df.ID_DATE == dim_date.NEW_ID_DATE, \"left\")\n",
    "    new_row_df = new_row_df.join(dim_info, new_row_df.ID_INFO_ACTION == dim_info.NEW_ID_INFO_ACTION, \"left\")\n",
    "    new_row_df = new_row_df.join(dim_revenue, new_row_df.ID_REVENUE == dim_revenue.NEW_ID_REVENUE, \"left\")\n",
    "   \n",
    "    #new_row_df.display()\n",
    "    checkandaddskdate(new_date_id, dim_date, data) \n",
    "    new_row_df1=new_row_df\n",
    "    new_row_df = new_row_df \\\n",
    "    .withColumn(\"ID_DATE\", when(col(\"NEW_ID_DATE\").isNull(), lit(data[\"Date\"])).otherwise(col(\"NEW_ID_DATE\"))) \\\n",
    "    .withColumn(\"ID_INFO_ACTION\", when(col(\"NEW_ID_INFO_ACTION\").isNull(), lit(new_info_id)).otherwise(col(\"NEW_ID_INFO_ACTION\")))\\\n",
    "    .withColumn(\"ID_REVENUE\", when(col(\"NEW_ID_REVENUE\").isNull(), lit(new_revenue_id)).otherwise(col(\"NEW_ID_REVENUE\")))\n",
    "    \n",
    "    # Select only the required columns for the Fact_product table and append the new row to the existing data\n",
    "    new_row_df = new_row_df.select(\"ID_ACTION\",\"ID_DATE\",\"ID_INFO_ACTION\", \"ID_DIVIDEND\",\"OPEN\",\"HIGHT\", \"LOW\",\"CLOSE\",\"VOLUME\" ,\n",
    "                                   \"ADJ_CLOSE\", \"ID_REVENUE\")\n",
    "    dim_date = dim_date.withColumnRenamed(\"NEW_ID_DATE\", \"ID_DATE\")\n",
    "    if new_row_df.collect()[0][2]==new_info_id:\n",
    "        checkandaddidinfoaction(new_row_df.collect()[0][2],dim_info,data)\n",
    "    if new_row_df.collect()[0][10]==new_revenue_id:\n",
    "        checkandaddidrevenue(new_row_df.collect()[0][10],dim_revenue,data)\n",
    "    # Save the DataFrame to the database table\n",
    "    \n",
    "    num_rows = new_row_df.count()\n",
    "    print(num_rows)\n",
    "    if ( num_rows >1 ):\n",
    "      first_row = new_row_df.limit(1)\n",
    "    else :\n",
    "      first_row=new_row_df\n",
    "    \n",
    "    existing_row = table_fait.filter(\n",
    "        (col(\"ID_DATE\") == new_row_df.collect()[0][1]) &\n",
    "        (col(\"ID_INFO_ACTION\") == new_row_df.collect()[0][2])\n",
    "    ).count() \n",
    "    if existing_row == 0:\n",
    "         first_row.write.format(\"jdbc\").option('url', url).option(\"dbtable\", \"fact_table\").mode(\"append\").save()\n",
    "         predict_volume_price(table_fait,first_row.collect()[0][2])\n",
    "         predict_close_price(table_fait,first_row.collect()[0][2])\n",
    "    else:\n",
    "        #raise Exception(\"Operation canceled. Conditions already exist in table_fait.\")\n",
    "        \n",
    "        return print(\"row already exist\")\n",
    "    \n",
    "    return new_row_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2998c43e-a7e5-424c-a37a-9b9a9c690ab0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data=data ={'Date': '20230420', 'Open': 161.4199981689, 'High': 162.0299987793, 'Low': 160.0800018311, 'Close': 162.0299987793, 'Adj Close': 161.8061828613, 'Volume': 47716900, 'company_name': 'GOOG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c18fbba9-4c03-4453-b2e1-44491e660e5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "from pyspark.sql.functions import col,lit,when\n",
    "import pyodbc\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a7b14e-dd60-4594-b254-5c54f29c6310",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "consommer les evenenement à partir de l'event hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f340ea2d-333f-41b6-bb6d-a85235cb3f0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "from pyspark.sql.functions import col,lit,when\n",
    "import pyodbc\n",
    "import time\n",
    "from azure.eventhub.aio import EventHubConsumerClient\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define the schema of the JSON\n",
    "json_schema = StructType([\n",
    "    StructField(\"Date\", StringType()),\n",
    "    StructField(\"Open\", DoubleType()),\n",
    "    StructField(\"High\", DoubleType()),\n",
    "    StructField(\"Low\", DoubleType()),\n",
    "    StructField(\"Close\", DoubleType()),\n",
    "    StructField(\"Adj Close\", DoubleType()),\n",
    "    StructField(\"Volume\", IntegerType()),\n",
    "    StructField(\"company_name\", StringType())\n",
    "])\n",
    "\n",
    "cs = 'Endpoint=sb://evenetstream.servicebus.windows.net/;SharedAccessKeyName=streamdata;SharedAccessKey=Hfd1AYOfca/hX5J7/EbtPcTySlWOUFesH+AEhK64OQY=;EntityPath=eventhub1'\n",
    "connection_string = cs + \";EntityPath=eventhub1\"\n",
    "\n",
    "conf = {}\n",
    "conf['eventhubs.connectionString'] = sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(connection_string)\n",
    "conf['eventhubs.consumerGroup'] = \"$Default\"\n",
    "\n",
    "# Load streaming data from eventhubs\n",
    "input_stream_df = spark.readStream.format(\"eventhubs\").options(**conf).option(\"startingOffsets\", \"earliest\").load()\n",
    "\n",
    "# Convert the \"body\" column to JSON structure\n",
    "body_df = input_stream_df.select(from_json(col(\"body\").cast(\"string\"), json_schema).alias(\"body_json\"))\n",
    "\n",
    "# Extract the JSON fields into separate columns\n",
    "body_df = body_df.select(\n",
    "    col(\"body_json.Date\"),\n",
    "    col(\"body_json.Open\"),\n",
    "    col(\"body_json.High\"),\n",
    "    col(\"body_json.Low\"),\n",
    "    col(\"body_json.Close\"),\n",
    "    col(\"body_json.`Adj Close`\").alias(\"Adj_Close\"),\n",
    "    col(\"body_json.Volume\"),\n",
    "    col(\"body_json.company_name\")\n",
    ")\n",
    "\n",
    "# Define the process_event function to handle events\n",
    "async def process_event(partition_context, event):\n",
    "    # Extract the data from the event body\n",
    "    event_body = ''.join(chunk.decode('utf-8') for chunk in event.body)\n",
    "    print(\"Event Body:\", event_body)\n",
    "    \n",
    "    # Convert the event body to a JSON object\n",
    "    event_data = json.loads(event_body)\n",
    "    \n",
    "    # Generate the new row DataFrame\n",
    "    new_row_df = generaterow(event_data)\n",
    "    new_row_df.show(truncate=False\n",
    "                   )\n",
    "    \n",
    "    # Save the DataFrame to the database table\n",
    "    #new_row_df.write.format(\"jdbc\").option('url', url).option(\"dbtable\", \"fait_test\").mode(\"append\").save()\n",
    "\n",
    "#print(\"Send messages in {} seconds.\".format(time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22106f0c-db95-44de-96c5-1599a091f2db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_fait = (spark.read.format(\"jdbc\").option(\"driver\", driver).option(\"url\", url).option(\"dbtable\", \"fact_table\").load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c5226a4-0996-4517-83b7-de95fcc6f865",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Body: {\"Date\": \"20230502\", \"Open\": 170.0899963379, \"High\": 170.3500061035, \"Low\": 167.5399932861, \"Close\": 168.5399932861, \"Adj Close\": 168.3071899414, \"Volume\": 48425700, \"company_name\": \"AAPL\"}\n47\nDate: 20230502\nPredicted value: 60724898.048870035\nTrue value: 48425700\nPercentage difference: 25.398080046070646\n+--------+---------+-----------+------+\n|   date_|   volume|volume_pred|ticker|\n+--------+---------+-----------+------+\n|20230502|4.84257E7|  6.07249E7|     2|\n+--------+---------+-----------+------+\n\nDate: 20230502\nPredicted value: 167.80765603035854\nTrue value: 168.5399932861\nPercentage difference: 0.4345183843091253\nAAPL\n+--------+------+---------------+------+\n|   date_|close_|predicted_close|ticker|\n+--------+------+---------------+------+\n|20230502|168.54|      167.80766|     2|\n+--------+------+---------------+------+\n\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\n|ID_ACTION|ID_DATE |ID_INFO_ACTION|ID_DIVIDEND|OPEN          |HIGHT         |LOW           |CLOSE         |VOLUME  |ADJ_CLOSE     |ID_REVENUE|\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n|16915    |20230502|2             |1          |170.0899963379|170.3500061035|167.5399932861|168.5399932861|48425700|168.3071899414|1         |\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\nonly showing top 20 rows\n\nEvent Body: {\"Date\": \"20230502\", \"Open\": 107.6600036621, \"High\": 107.7300033569, \"Low\": 104.5, \"Close\": 105.9800033569, \"Adj Close\": 105.9800033569, \"Volume\": 20343100, \"company_name\": \"GOOG\"}\n53\nDate: 20230502\nPredicted value: 26424238.518974062\nTrue value: 20343100\nPercentage difference: 29.89288023444835\n+--------+---------+-----------+------+\n|   date_|   volume|volume_pred|ticker|\n+--------+---------+-----------+------+\n|20230502|2.03431E7|2.6424238E7|     4|\n+--------+---------+-----------+------+\n\nDate: 20230502\nPredicted value: 106.91693278237351\nTrue value: 105.9800033569\nPercentage difference: 0.884062460649571\nAAPL\n+--------+------+---------------+------+\n|   date_|close_|predicted_close|ticker|\n+--------+------+---------------+------+\n|20230502|105.98|      106.91693|     4|\n+--------+------+---------------+------+\n\n+---------+--------+--------------+-----------+--------------+--------------+-----+--------------+--------+--------------+----------+\n|ID_ACTION|ID_DATE |ID_INFO_ACTION|ID_DIVIDEND|OPEN          |HIGHT         |LOW  |CLOSE         |VOLUME  |ADJ_CLOSE     |ID_REVENUE|\n+---------+--------+--------------+-----------+--------------+--------------+-----+--------------+--------+--------------+----------+\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n|16916    |20230502|4             |1          |107.6600036621|107.7300033569|104.5|105.9800033569|20343100|105.9800033569|2         |\n+---------+--------+--------------+-----------+--------------+--------------+-----+--------------+--------+--------------+----------+\nonly showing top 20 rows\n\nEvent Body: {\"Date\": \"20230502\", \"Open\": 307.7600097656, \"High\": 309.1799926758, \"Low\": 303.9100036621, \"Close\": 305.4100036621, \"Adj Close\": 304.7438049316, \"Volume\": 26404400, \"company_name\": \"MSFT\"}\n33\nDate: 20230502\nPredicted value: 24372659.081851106\nTrue value: 26404400\nPercentage difference: 7.694705875342343\n+--------+---------+-----------+------+\n|   date_|   volume|volume_pred|ticker|\n+--------+---------+-----------+------+\n|20230502|2.64044E7| 2.437266E7|     6|\n+--------+---------+-----------+------+\n\nDate: 20230502\nPredicted value: 303.6303164849251\nTrue value: 305.4100036621\nPercentage difference: 0.5827206561131153\nAAPL\n+--------+------+---------------+------+\n|   date_|close_|predicted_close|ticker|\n+--------+------+---------------+------+\n|20230502|305.41|       303.6303|     6|\n+--------+------+---------------+------+\n\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\n|ID_ACTION|ID_DATE |ID_INFO_ACTION|ID_DIVIDEND|OPEN          |HIGHT         |LOW           |CLOSE         |VOLUME  |ADJ_CLOSE     |ID_REVENUE|\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n|16917    |20230502|6             |1          |307.7600097656|309.1799926758|303.9100036621|305.4100036621|26404400|304.7438049316|3         |\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\nonly showing top 20 rows\n\nEvent Body: {\"Date\": \"20230502\", \"Open\": 101.4700012207, \"High\": 103.9000015259, \"Low\": 101.1500015259, \"Close\": 103.6299972534, \"Adj Close\": 103.6299972534, \"Volume\": 73469400, \"company_name\": \"AMZN\"}\n21\nDate: 20230502\nPredicted value: 78702735.24951276\nTrue value: 73469400\nPercentage difference: 7.123149569089664\n+--------+---------+-----------+------+\n|   date_|   volume|volume_pred|ticker|\n+--------+---------+-----------+------+\n|20230502|7.34694E7|7.8702736E7|     3|\n+--------+---------+-----------+------+\n\nDate: 20230502\nPredicted value: 102.82040804862731\nTrue value: 103.6299972534\nPercentage difference: 0.7812305570104897\nAAPL\n+--------+------+---------------+------+\n|   date_|close_|predicted_close|ticker|\n+--------+------+---------------+------+\n|20230502|103.63|      102.82041|     3|\n+--------+------+---------------+------+\n\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\n|ID_ACTION|ID_DATE |ID_INFO_ACTION|ID_DIVIDEND|OPEN          |HIGHT         |LOW           |CLOSE         |VOLUME  |ADJ_CLOSE     |ID_REVENUE|\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n|16918    |20230502|3             |1          |101.4700012207|103.9000015259|101.1500015259|103.6299972534|73469400|103.6299972534|4         |\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+--------+--------------+----------+\nonly showing top 20 rows\n\nEvent Body: {\"Date\": \"20230502\", \"Open\": 13.8299999237, \"High\": 13.8699998856, \"Low\": 13.5200004578, \"Close\": 13.7700004578, \"Adj Close\": 13.7700004578, \"Volume\": 22469800, \"company_name\": \"AAL\"}\n23\nDate: 20230502\nPredicted value: 33510611.63184698\nTrue value: 22469800\nPercentage difference: 49.1362256533079\n+--------+---------+-----------+------+\n|   date_|   volume|volume_pred|ticker|\n+--------+---------+-----------+------+\n|20230502|2.24698E7|3.3510612E7|     1|\n+--------+---------+-----------+------+\n\nDate: 20230502\nPredicted value: 13.979166690732768\nTrue value: 13.7700004578\nPercentage difference: 1.5189994624458125\nAAPL\n+--------+------+---------------+------+\n|   date_|close_|predicted_close|ticker|\n+--------+------+---------------+------+\n|20230502| 13.77|      13.979167|     1|\n+--------+------+---------------+------+\n\n+---------+--------+--------------+-----------+-------------+-------------+-------------+-------------+--------+-------------+----------+\n|ID_ACTION|ID_DATE |ID_INFO_ACTION|ID_DIVIDEND|OPEN         |HIGHT        |LOW          |CLOSE        |VOLUME  |ADJ_CLOSE    |ID_REVENUE|\n+---------+--------+--------------+-----------+-------------+-------------+-------------+-------------+--------+-------------+----------+\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n|16919    |20230502|1             |1          |13.8299999237|13.8699998856|13.5200004578|13.7700004578|22469800|13.7700004578|5         |\n+---------+--------+--------------+-----------+-------------+-------------+-------------+-------------+--------+-------------+----------+\nonly showing top 20 rows\n\nEvent Body: {\"Date\": \"20230502\", \"Open\": 108.3899993896, \"High\": 108.6100006104, \"Low\": 105.6900024414, \"Close\": 107.1100006104, \"Adj Close\": 106.6972427368, \"Volume\": 2163500, \"company_name\": \"ICE\"}\n24\nDate: 20230502\nPredicted value: 2204477.6941667497\nTrue value: 2163500\nPercentage difference: 1.8940464139935158\n+--------+---------+-----------+------+\n|   date_|   volume|volume_pred|ticker|\n+--------+---------+-----------+------+\n|20230502|2163500.0|  2204477.8|     5|\n+--------+---------+-----------+------+\n\nDate: 20230502\nPredicted value: 107.69769721119668\nTrue value: 107.1100006104\nPercentage difference: 0.5486850877112466\nAAPL\n+--------+------+---------------+------+\n|   date_|close_|predicted_close|ticker|\n+--------+------+---------------+------+\n|20230502|107.11|       107.6977|     5|\n+--------+------+---------------+------+\n\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+-------+--------------+----------+\n|ID_ACTION|ID_DATE |ID_INFO_ACTION|ID_DIVIDEND|OPEN          |HIGHT         |LOW           |CLOSE         |VOLUME |ADJ_CLOSE     |ID_REVENUE|\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+-------+--------------+----------+\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n|16920    |20230502|5             |1          |108.3899993896|108.6100006104|105.6900024414|107.1100006104|2163500|106.6972427368|6         |\n+---------+--------+--------------+-----------+--------------+--------------+--------------+--------------+-------+--------------+----------+\nonly showing top 20 rows\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "# Start consuming events from the Event Hub\n",
    "client = EventHubConsumerClient.from_connection_string(\n",
    "    conn_str=cs,\n",
    "    consumer_group=\"$Default\",\n",
    "     eventhub_name=\"eventhub1\"\n",
    "     )\n",
    "async def consume_events():\n",
    "    await client.receive(\n",
    "        on_event=process_event,\n",
    "        starting_position=\"@latest\",  # Start from the beginning of the event stream\n",
    "    )\n",
    "\n",
    "await consume_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a097445-4c71-4719-9fda-6c74246aa05c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4181463285483916,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "final consumer",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
